# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

from typing import List, Set, Tuple, Optional, Any
from queue import PriorityQueue
import numpy as np
import logging

from graphrag_toolkit.lexical_graph.metadata import FilterConfig
from graphrag_toolkit.lexical_graph.storage.graph import GraphStore
from graphrag_toolkit.lexical_graph.storage.vector import VectorStore
from graphrag_toolkit.lexical_graph.retrieval.utils.statement_utils import (
    get_top_k,
    SharedEmbeddingCache,
)
from graphrag_toolkit.lexical_graph.retrieval.retrievers.semantic_guided_base_retriever import (
    SemanticGuidedBaseRetriever,
)

from llama_index.core.schema import NodeWithScore, QueryBundle, TextNode

logger = logging.getLogger(__name__)


class SemanticBeamGraphSearch(SemanticGuidedBaseRetriever):
    """A class that implements a semantic-guided beam search algorithm on a
    graph-based data store, facilitating retrieval tasks involving entity
    relationships and embedding-based similarity.

    The `SemanticBeamGraphSearch` class builds upon a base retriever to utilize a combination of graph-based
    neighbor expansion and beam search heuristic optimization. It is designed to process queries, traverse
    entities and their connections in a graph, and return the most relevant statements using an embedding-based
    ranking approach. The class also integrates optional cache mechanisms for embeddings and allows flexibility
    in configuration such as search depth and beam width.

    Attributes:
        embedding_cache (Optional[SharedEmbeddingCache]): Shared cache of embeddings for faster retrieval.
        max_depth (int): Maximum number of graph traversal levels during beam search.
        beam_width (int): Number of candidate states to consider at each step in the beam search.
        shared_nodes (Optional[List[NodeWithScore]]): Initial shared nodes to derive the starting points.
    """

    def __init__(
        self,
        vector_store: VectorStore,
        graph_store: GraphStore,
        embedding_cache: Optional[SharedEmbeddingCache] = None,
        max_depth: int = 3,
        beam_width: int = 10,
        shared_nodes: Optional[List[NodeWithScore]] = None,
        filter_config: Optional[FilterConfig] = None,
        **kwargs: Any,
    ) -> None:
        """Initializes a class that manages the connection between a vector
        store, a graph store, and an optional embedding cache, allowing complex
        data structure processing through specific search depth and beam width
        configurations.

        Args:
            vector_store: The storage facility adhering to the VectorStore interface for
                vector data retrieval and management.
            graph_store: The storage facility adhering to the GraphStore interface for
                graph structure data retrieval and manipulation.
            embedding_cache: An optional shared embedding cache for reusing embeddings,
                reducing computation for repeated queries.
            max_depth: The maximum depth for graph traversals, controlling the scope of
                the search or processing operations.
            beam_width: The beam width determining the number of nodes considered at
                each level of the traversal during the search operation.
            shared_nodes: An optional list of node-score mappings representing pre-shared
                nodes to be considered during operation.
            filter_config: Optional configuration for applying filters to the results or
                operations performed within the system.
            **kwargs: Additional keyword arguments passed to the superclass initializer.
        """
        super().__init__(vector_store, graph_store, filter_config, **kwargs)
        self.embedding_cache = embedding_cache
        self.max_depth = max_depth
        self.beam_width = beam_width
        self.shared_nodes = shared_nodes

    def get_neighbors(self, statement_id: str) -> List[str]:
        """Fetches the neighboring statement IDs in the graph, where
        neighboring statements are associated with any entities connected to
        the given statement.

        This method queries the graph database to identify entities that are directly linked to the
        provided statement and retrieves other statements supported by these entities.

        Args:
            statement_id: The ID of the statement for which to fetch neighboring statements.

        Returns:
            List[str]: A list of statement IDs that are neighbors to the given statement ID.
        """
        cypher = f"""
        MATCH (e:`__Entity__`)-[:`__SUBJECT__`|`__OBJECT__`]->(:`__Fact__`)-[:`__SUPPORTS__`]->(s:`__Statement__`)
        WHERE {self.graph_store.node_id('s.statementId')} = $statementId
        WITH s, COLLECT(DISTINCT e) AS entities
        UNWIND entities AS entity
        MATCH (entity)-[:`__SUBJECT__`|`__OBJECT__`]->(:`__Fact__`)-[:`__SUPPORTS__`]->(e_neighbors:`__Statement__`)
        RETURN DISTINCT {self.graph_store.node_id('e_neighbors.statementId')} as statementId
        """

        neighbors = self.graph_store.execute_query(
            cypher, {'statementId': statement_id}
        )
        return [n['statementId'] for n in neighbors]

    def beam_search(
        self, query_embedding: np.ndarray, start_statement_ids: List[str]
    ) -> List[Tuple[str, List[str]]]:  # [(statement_id, path), ...]
        """Performs a beam search to find the most relevant paths based on the
        provided query embedding.

        The search starts from given initial statement IDs and explores their neighbors up to a maximum
        depth. It uses a priority queue to ensure that the paths with the highest similarity scores
        are evaluated first. The method stops when the beam width (the maximum number of results)
        is reached or when no more relevant neighbors are found.

        Args:
            query_embedding (np.ndarray): The embedding vector representing the query for
                similarity comparison.
            start_statement_ids (List[str]): A list of statement IDs to start the beam search from.

        Returns:
            List[Tuple[str, List[str]]]: A list of tuples where each tuple consists of a statement ID
            and its corresponding path of IDs that led to it. The length of the returned list does
            not exceed the beam width.
        """
        visited: Set[str] = set()
        results: List[Tuple[str, List[str]]] = []
        queue: PriorityQueue = PriorityQueue()

        # Get initial embeddings and scores
        start_embeddings = self.embedding_cache.get_embeddings(start_statement_ids)
        start_scores = get_top_k(
            query_embedding, start_embeddings, len(start_statement_ids)
        )

        # Initialize queue with start statements
        for similarity, statement_id in start_scores:
            queue.put((-similarity, 0, statement_id, [statement_id]))

        while not queue.empty() and len(results) < self.beam_width:
            neg_score, depth, current_id, path = queue.get()

            if current_id in visited:
                continue

            visited.add(current_id)
            results.append((current_id, path))

            if depth < self.max_depth:
                neighbor_ids = self.get_neighbors(current_id)

                if neighbor_ids:
                    # Get embeddings for neighbors using shared cache
                    neighbor_embeddings = self.embedding_cache.get_embeddings(
                        neighbor_ids
                    )

                    # Score neighbors
                    scored_neighbors = get_top_k(
                        query_embedding, neighbor_embeddings, self.beam_width
                    )

                    # Add neighbors to queue
                    for similarity, neighbor_id in scored_neighbors:
                        if neighbor_id not in visited:
                            new_path = path + [neighbor_id]
                            queue.put((-similarity, depth + 1, neighbor_id, new_path))

        return results

    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        """Retrieves nodes relevant to a query by performing an initial
        extraction of statement IDs either from shared nodes or through a
        fallback vector similarity search, followed by a beam search to further
        refine the results. Constructs new nodes for any statements not already
        processed.

        Args:
            query_bundle (QueryBundle): The input query packaged as a QueryBundle
                object, containing the query and its associated metadata.

        Returns:
            List[NodeWithScore]: A list of `NodeWithScore` objects representing the
                nodes corresponding to the retrieved statements, along with their
                associated scores.
        """
        # 1. Get initial nodes (either shared or fallback)
        initial_statement_ids = []
        if self.shared_nodes:
            initial_statement_ids = [
                n.node.metadata['statement']['statementId'] for n in self.shared_nodes
            ]
        else:
            # Fallback to vector similarity
            results = self.vector_store.get_index('statement').top_k(
                query_bundle,
                top_k=self.beam_width * 2,
                filter_config=self.filter_config,
            )
            initial_statement_ids = [r['statement']['statementId'] for r in results]

        if logger.isEnabledFor(logging.DEBUG) and self.debug_results:
            logger.debug(f'initial_statement_ids: {initial_statement_ids}')
        else:
            logger.debug(f'num initial_statement_ids: {len(initial_statement_ids)}')

        if not initial_statement_ids:
            return []

        # 2. Perform beam search
        beam_results = self.beam_search(query_bundle.embedding, initial_statement_ids)

        if logger.isEnabledFor(logging.DEBUG) and self.debug_results:
            logger.debug(f'beam_results: {beam_results}')
        else:
            logger.debug(f'num beam_results: {len(beam_results)}')

        # 3. Create nodes for new statements only
        nodes = []
        initial_ids = set(initial_statement_ids)
        for statement_id, path in beam_results:
            if statement_id not in initial_ids:
                node = TextNode(
                    text="",  # Placeholder
                    metadata={
                        'statement': {'statementId': statement_id},
                        'search_type': 'beam_search',
                        'depth': len(path),
                        'path': path,
                    },
                )
                nodes.append(NodeWithScore(node=node, score=0.0))

        if logger.isEnabledFor(logging.DEBUG) and self.debug_results:
            logger.debug(f'nodes: {nodes}')
        else:
            logger.debug(f'num nodes: {len(nodes)}')

        return nodes
